# config.py
import numpy as np
from multiprocessing import cpu_count

import torch
if torch.cuda.is_available():
    selected_device = "cuda:0"
    selected_backend = "nccl"
else:
    selected_device = "cpu"
    selected_backend = "gloo"


# Define the data type.
IntegerTypes = np.uint32

# Define default configuration values.
DEFAULT_CONFIG = {
    "data_process": {
        "train_split_ratio": 0.9,
        "no_validation": False,
        "use_gpt2_tokenizer": True,
        "num_proc": cpu_count() // 2
    },
    "training": {
        "out_dir": "out",
        "plot_interval": 10,
        "log_interval": 10,
        "num_eval_seeds": 0,
        "save_best_val_checkpoint": True,
        "init_from": "scratch",
        "gradient_accumulation_steps": 1,
        "batch_size": 32,
        "block_size": 256,
        "n_layer": 6,
        "n_head": 6,
        "n_embd": 384,
        "dropout": 0.1,
        "bias": True,
        "learning_rate": 1e-3,
        "max_iters": 300,
        "weight_decay": 1e-2,
        "beta1": 0.9,
        "beta2": 0.999,
        "lr_scheduler_type": "cosine",
        "warmup_iters": 10,
        "lr_decay_iters": 300,
        "min_lr": 1e-5,
        "step_size": 150,
        "step_gamma": 0.1,
        "polynomial_power": 2.0,
        "backend": selected_backend,
        "device": selected_device,
        "dtype": "float16",
        "compile_model": False,
        "seed": 1024,
        "save_interval": 50,
        # Self-attention specific parameters
        "use_self_attention": False,
        "ffn_hidden_mult": 4,
        "qkv_bias": True,
        "attn_dropout": 0.1,
        "resid_dropout": 0.1,
        "ln_eps": 1e-5,
        "init_std": 0.02,
        "use_flash_attn": False,
        "pos_encoding_type": "rope",
        "rope_base": 10000,
        "rope_cache_size": 1024,  # Dynamic RoPE cache size (None for auto)
        "alibi_bias_scale": 1.0,  # ALiBi bias scaling factor
        "ffn_activation": "gelu",  # FFN activation function: gelu, relu, swish
        "attention_scale_factor": 1.0,  # Additional attention scaling
        "gradient_checkpointing": False,  # Memory-efficient training
        # Memory management
        "cache_strategy": "adaptive",  # Cache allocation strategy: adaptive, fixed, minimal
        "max_cache_size": 4096,  # Maximum cache size for dynamic allocation
        # Error handling
        "strict_validation": True,  # Enable strict input validation
        "fallback_on_error": True  # Fallback to basic implementations on error
    },
    "inference": {
        "out_dir": "out",
        "prompt": "",
        "num_samples": 3,
        "max_new_tokens": 64,
        "temperature": 0.7,
        "top_k": 50,
        "seed": 1024,
        "device": selected_device,
        "dtype": "float16",
        "compile_model": False
    }
}

# Multilingual support
LANG_JSON = {
    "en": {
        "app_title": "Mini Nano GPT",
        "language_label": "Language",
        "data_process_tab": "Data Processing",
        "train_tab": "Training",
        "infer_tab": "Inference",
        "compare_tab": "Comparison",
        "model_tab": "Model Management",

        "registered_models": "Registered Models",
        "refresh_tables": "Refresh",
        "delete_selected_model": "Delete Selected Model",

        "new_model": "New Model",
        "model_name": "Model Name",

        "dp_paste_text": "Paste Text",
        "dp_txt_dir": "TXT Directory (Optional)",
        "dp_raw_dir": "Raw Data Directory",
        "dp_processed_dir": "Processed Data Directory",
        "dp_train_split": "Training Split Ratio",
        "dp_no_val_set": "Do not use validation set",
        "dp_use_gpt2_tokenizer": "Use GPT-2/Qwen Tokenizer",
        "dp_num_proc": "Number of Processes",
        "dp_start_btn": "Start Processing",
        "dp_result": "Processing Result",

        "train_params_title": "Training Parameters",
        "train_data_dir": "Data Directory (where train.bin/val.bin)",
        "train_out_dir": "Output Directory",
        "train_eval_interval": "Plot Interval",
        "train_log_interval": "Logging Interval",
        "train_num_eval_seeds": "Number of Evaluation Seeds",
        "train_save_best_val_ckpt": "Save Best Val Loss Checkpoint",
        "train_init_from": "Initialization Source",
        "train_gas": "Gradient Accumulation Steps",
        "train_batch_size": "Batch Size",
        "train_block_size": "Block Size",
        "train_n_layer": "Number of Layers",
        "train_n_head": "Number of Attention Heads",
        "train_n_embd": "Embedding Dimension",
        "train_dropout": "Dropout Rate",
        "train_bias": "Use Bias",
        "train_lr": "Learning Rate",
        "train_max_iters": "Maximum Iterations",
        "train_weight_decay": "Weight Decay",
        "train_beta1": "Beta 1",
        "train_beta2": "Beta 2",
        "train_lr_scheduler": "Learning Rate Scheduler",
        "train_warmup_iters": "Warmup Iterations",
        "train_lr_decay_iters": "Learning Rate Decay Iterations",
        "train_min_lr": "Minimum Learning Rate",
        "train_step_size": "Step Size",
        "train_step_gamma": "Step Gamma",
        "train_poly_power": "Polynomial Power",
        "train_backend": "Backend",
        "train_device": "Device",
        "train_dtype": "Data Type",
        "train_compile_model": "Compile Model",
        "train_start_btn": "Start Training",
        "train_log": "Training Log",
        "train_plot": "Loss Curve",
        "train_seed": "Seed",
        "train_save_interval": "Save Interval (Steps)",

        # Self-attention parameters
        "train_self_attn_title": "Self-Attention Parameters",
        "train_use_self_attention": "Enable Self-Attention",
        "train_ffn_hidden_mult": "FFN Hidden Multiplier",
        "train_qkv_bias": "QKV Bias",
        "train_attn_dropout": "Attention Dropout",
        "train_resid_dropout": "Residual Dropout",
        "train_ln_eps": "Layer Norm Epsilon",
        "train_init_std": "Weight Init Std",
        "train_use_flash_attn": "Use Flash Attention",
        "train_pos_encoding_type": "Position Encoding",
        "train_rope_base": "RoPE Base",

        # New optimized parameters
        "train_rope_cache_size": "RoPE Cache Size",
        "train_alibi_bias_scale": "ALiBi Bias Scale",
        "train_ffn_activation": "FFN Activation",
        "train_attention_scale_factor": "Attention Scale",
        "train_gradient_checkpointing": "Gradient Checkpointing",
        "train_cache_strategy": "Cache Strategy",
        "train_max_cache_size": "Max Cache Size",
        "train_strict_validation": "Strict Validation",
        "train_fallback_on_error": "Fallback on Error",

        "inf_out_dir": "Model Directory (ckpt.pt)",
        "inf_prompt": "Prompt",
        "inf_num_samples": "Number of Samples",
        "inf_max_new_tokens": "Maximum New Tokens",
        "inf_temperature": "Temperature",
        "inf_top_k": "Top K",
        "inf_dtype": "Data Type",
        "inf_start_btn": "Generate",
        "inf_result": "Generation Result",
        "inf_seed": "Seed",
        "inf_device": "Inference Device",
        "stop_btn": "Stop Training",

        "model_new": "Create New Model",
        "model_name": "Model Name",
        "model_description": "Description",
        "model_select": "Select Model",
        "model_create_btn": "Create",
        "model_delete_btn": "Delete",
        "model_save_btn": "Save",
        "model_list": "Model List",
        "model_current": "Current Model",
        "model_id": "ID",
        "model_create_time": "Created",
        "model_update_time": "Updated",
        "model_dir": "Directory",
        
        "compare_left_model": "Left",
        "compare_right_model": "Right",
        "compare_model_params": "Model Parameters",
        "compare_loss_curve": "Loss Curve",
        "compare_inference_history": "Inference History",
        "compare_inference_playground": "Playground",
        "compare_inference_params": "Inference Parameters",
        "compare_generate_btn": "Generate",
        "compare_shared_prompt": "Shared Prompt",
        "compare_left_output": "Left Model Output",
        "compare_right_output": "Right Model Output"
    },
    "fr": {
        "app_title": "Mini Nano GPT",
        "language_label": "Langue",
        "data_process_tab": "Traitement des données",
        "train_tab": "Entraînement",
        "infer_tab": "Inférence",
        "compare_tab": "Comparaison",
        "model_tab": "Gestion des modèles",

        "registered_models": "Modèles enregistrés",
        "refresh_tables": "Actualiser",
        "delete_selected_model": "Supprimer le modèle sélectionné",

        "new_model": "Nouveau modèle",
        "model_name": "Nom du modèle",

        "dp_paste_text": "Coller le texte",
        "dp_txt_dir": "Répertoire TXT (Optionnel)",
        "dp_raw_dir": "Répertoire des données brutes",
        "dp_processed_dir": "Répertoire des données traitées",
        "dp_train_split": "Ratio de division pour l'entraînement",
        "dp_no_val_set": "Ne pas utiliser d'ensemble de validation",
        "dp_use_gpt2_tokenizer": "Utiliser le tokenizer GPT-2/Qwen",
        "dp_num_proc": "Nombre de processus",
        "dp_start_btn": "Démarrer le traitement",
        "dp_result": "Résultat du traitement",

        "train_params_title": "Paramètres d'entraînement",
        "train_data_dir": "Répertoire de données (où se trouvent train.bin/val.bin)",
        "train_out_dir": "Répertoire de sortie",
        "train_eval_interval": "Intervalle de traçage",
        "train_log_interval": "Intervalle de journalisation",
        "train_num_eval_seeds": "Nombre de graines d'évaluation",
        "train_save_best_val_ckpt": "Enregistrer le meilleur point de contrôle de perte de validation",
        "train_init_from": "Source d'initialisation",
        "train_gas": "Étapes d'accumulation de gradient",
        "train_batch_size": "Taille du lot",
        "train_block_size": "Taille du bloc",
        "train_n_layer": "Nombre de couches",
        "train_n_head": "Nombre de têtes d'attention",
        "train_n_embd": "Dimension de l'incorporation",
        "train_dropout": "Taux de décrochage",
        "train_bias": "Utiliser le biais",
        "train_lr": "Taux d'apprentissage",
        "train_max_iters": "Itérations maximales",
        "train_weight_decay": "Décroissance du poids",
        "train_beta1": "Bêta 1",
        "train_beta2": "Bêta 2",
        "train_lr_scheduler": "Planificateur de taux d'apprentissage",
        "train_warmup_iters": "Itérations de préchauffage",
        "train_lr_decay_iters": "Itérations de décroissance du taux d'apprentissage",
        "train_min_lr": "Taux d'apprentissage minimum",
        "train_step_size": "Taille du pas",
        "train_step_gamma": "Gamma du pas",
        "train_poly_power": "Puissance polynomiale",
        "train_backend": "Backend",
        "train_device": "Appareil",
        "train_dtype": "Type de données",
        "train_compile_model": "Compiler le modèle",
        "train_start_btn": "Démarrer l'entraînement",
        "train_log": "Journal d'entraînement",
        "train_plot": "Courbe de perte",
        "train_seed": "Graine",
        "train_save_interval": "Intervalle de sauvegarde (étapes)",

        # Self-attention parameters
        "train_self_attn_title": "Paramètres d'auto-attention",
        "train_use_self_attention": "Activer l'auto-attention",
        "train_ffn_hidden_mult": "Multiplicateur caché FFN",
        "train_qkv_bias": "Biais QKV",
        "train_attn_dropout": "Décrochage de l'attention",
        "train_resid_dropout": "Décrochage résiduel",
        "train_ln_eps": "Epsilon de la norme de couche",
        "train_init_std": "Écart type d'initialisation des poids",
        "train_use_flash_attn": "Utiliser Flash Attention",
        "train_pos_encoding_type": "Encodage de position",
        "train_rope_base": "Base RoPE",

        # New optimized parameters
        "train_rope_cache_size": "Taille du cache RoPE",
        "train_alibi_bias_scale": "Échelle du biais ALiBi",
        "train_ffn_activation": "Activation FFN",
        "train_attention_scale_factor": "Échelle d'attention",
        "train_gradient_checkpointing": "Point de contrôle du gradient",
        "train_cache_strategy": "Stratégie de cache",
        "train_max_cache_size": "Taille maximale du cache",
        "train_strict_validation": "Validation stricte",
        "train_fallback_on_error": "Repli en cas d'erreur",

        "inf_out_dir": "Répertoire du modèle (ckpt.pt)",
        "inf_prompt": "Invite",
        "inf_num_samples": "Nombre d'échantillons",
        "inf_max_new_tokens": "Nombre maximum de nouveaux jetons",
        "inf_temperature": "Température",
        "inf_top_k": "Top K",
        "inf_dtype": "Type de données",
        "inf_start_btn": "Générer",
        "inf_result": "Résultat de la génération",
        "inf_seed": "Graine",
        "inf_device": "Appareil d'inférence",
        "stop_btn": "Arrêter l'entraînement",

        "model_new": "Créer un nouveau modèle",
        "model_name": "Nom du modèle",
        "model_description": "Description",
        "model_select": "Sélectionner le modèle",
        "model_create_btn": "Créer",
        "model_delete_btn": "Supprimer",
        "model_save_btn": "Enregistrer",
        "model_list": "Liste des modèles",
        "model_current": "Modèle actuel",
        "model_id": "ID",
        "model_create_time": "Créé",
        "model_update_time": "Mis à jour",
        "model_dir": "Répertoire",

        "compare_left_model": "Gauche",
        "compare_right_model": "Droite",
        "compare_model_params": "Paramètres du modèle",
        "compare_loss_curve": "Courbe de perte",
        "compare_inference_history": "Historique de l'inférence",
        "compare_inference_playground": "Playground",
        "compare_inference_params": "Paramètres d'inférence",
        "compare_generate_btn": "Générer",
        "compare_shared_prompt": "Invite partagée",
        "compare_left_output": "Sortie du modèle de gauche",
        "compare_right_output": "Sortie du modèle de droite"
    }
}