[**English**](https://github.com/ystemsrx/mini-nanoGPT) | [ç®€ä½“ä¸­æ–‡](README.zh.md) | [FranÃ§ais](README.fr.md)

# Mini NanoGPT ğŸš€

#### EntraÃ®ner un GPT peut vraiment Ãªtre aussi simple ?

> Rendre l'entraÃ®nement de GPT amusant et accessible ! Une plateforme d'entraÃ®nement visuelle basÃ©e sur [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT).

## ğŸ“– Qu'est-ce que c'est ?

Mini-NanoGPT est un outil qui vous aide Ã  dÃ©marrer avec l'entraÃ®nement de modÃ¨les GPT sans effort. Que vous soyez :

* ğŸ“ Un dÃ©butant en apprentissage profond
* ğŸ‘¨â€ğŸ”¬ Un chercheur
* ğŸ› ï¸ Un dÃ©veloppeur

Ou simplement curieux des grands modÃ¨les de langage et que vous vouliez expÃ©rimenter leur magie,

Vous pouvez entraÃ®ner un modÃ¨le via une interface graphique intuitive !

> Pour la version originale de Mini NanoGPT (qui n'est plus mise Ã  jour), veuillez consulter la branche [**old**](https://github.com/ystemsrx/mini-nanoGPT/tree/old).

## âœ¨ FonctionnalitÃ©s clÃ©s

### 1. Facile Ã  utiliser

* ğŸ“± **Interface visuelle** : Dites adieu Ã  la ligne de commande ; cliquez pour commencer l'entraÃ®nement
* ğŸŒ **Interface utilisateur bilingue** : Prise en charge complÃ¨te des interfaces en anglais et en chinois
* ğŸ¯ **OpÃ©rations en un clic** : PrÃ©traitement des donnÃ©es, entraÃ®nement et gÃ©nÃ©ration de texte â€” le tout en un seul clic

### 2. FonctionnalitÃ©s puissantes

* ğŸ”¤ **Tokenisation flexible** : Prend en charge les tokenizers au niveau des caractÃ¨res et GPT-2/Qwen, avec prise en charge multilingue
* ğŸš„ **EntraÃ®nement efficace** : Prend en charge l'accÃ©lÃ©ration multi-processus et l'entraÃ®nement distribuÃ©
* ğŸ“Š **RÃ©troaction en temps rÃ©el** : Affichage en direct de la progression de l'entraÃ®nement et des performances
* âš™ï¸ **Visualisation des paramÃ¨tres** : Tous les paramÃ¨tres d'entraÃ®nement peuvent Ãªtre ajustÃ©s directement dans l'interface utilisateur
* ğŸ§© **Base de donnÃ©es de modÃ¨les** : GÃ©rez facilement les modÃ¨les et rÃ©utilisez les paramÃ¨tres d'entraÃ®nement Ã  tout moment

## ğŸš€ DÃ©marrage rapide

### Option 1 : DÃ©ploiement avec Docker (RecommandÃ©) ğŸ³

Le moyen le plus simple de commencer !

```bash
# Cloner le dÃ©pÃ´t
git clone --depth 1 https://github.com/ystemsrx/mini-nanoGPT.git
cd mini-nanogpt

# DÃ©marrer avec Docker Compose (recommandÃ©)
docker-compose up --build

# Ou construire et exÃ©cuter manuellement
docker build -t mini-nanogpt .
docker run --gpus all -p 7860:7860 -v $(pwd)/data:/app/data mini-nanogpt
```

Cela construira automatiquement l'image Docker et exÃ©cutera le conteneur. Le conteneur dÃ©tectera automatiquement votre environnement systÃ¨me (CPU/GPU). Pendant ce temps, les rÃ©pertoires `data`, `models` et `assets` du rÃ©pertoire de travail actuel seront montÃ©s dans le conteneur, vous permettant de stocker des donnÃ©es directement dans ces rÃ©pertoires.

Une fois dÃ©marrÃ©, visitez http://localhost:7860 pour accÃ©der Ã  l'application.

### Option 2 : Installation locale

Tout d'abord, crÃ©ez un environnement virtuel avec une version de Python jusqu'Ã  3.12. Ceci est nÃ©cessaire en raison des compatibilitÃ©s avec `torch` 2.0.

**Avec bash :**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Avec PowerShell :**
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

Une fois l'environnement virtuel activÃ©, installez les dÃ©pendances :
```bash
# Cloner le dÃ©pÃ´t
git clone --depth 1 https://github.com/ystemsrx/mini-nanoGPT.git
cd mini-nanogpt

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2. Lancer l'application

```bash
python app.py
```

Ouvrez le lien affichÃ© dans votre navigateur (gÃ©nÃ©ralement [http://localhost:7860](http://localhost:7860)) pour voir l'interface d'entraÃ®nement !

## ğŸ® Guide de l'utilisateur

### Ã‰tape 1 : PrÃ©parer les donnÃ©es

* Ouvrez la page "Traitement des donnÃ©es", collez votre texte d'entraÃ®nement et choisissez une mÃ©thode de tokenisation. Pour de meilleurs rÃ©sultats, cochez l'option d'utiliser un tokenizer â€” il construira automatiquement un vocabulaire basÃ© sur votre texte.
* Si vous ne voulez pas utiliser d'ensemble de validation, cochez l'option "Sauter l'ensemble de validation".
* Cliquez sur "DÃ©marrer le traitement" lorsque vous avez terminÃ©.

Voici un petit exemple pour la dÃ©monstration :

![Traitement des donnÃ©es](https://github.com/ystemsrx/mini-nanoGPT/blob/master/assets/imgs/en_data_process.png?raw=true)

### Ã‰tape 2 : EntraÃ®ner le modÃ¨le

* Passez Ã  la page "EntraÃ®nement" et ajustez les paramÃ¨tres si nÃ©cessaire (ou laissez-les par dÃ©faut pour un essai rapide).
* Les courbes de perte d'entraÃ®nement et de validation sont affichÃ©es en temps rÃ©el. Si vous avez gÃ©nÃ©rÃ© un ensemble de validation Ã  l'Ã©tape 1, vous devriez voir deux courbes : bleue pour la perte d'entraÃ®nement, orange pour la perte de validation.
* Si une seule courbe est affichÃ©e, vÃ©rifiez la sortie du terminal. Si vous voyez une erreur comme :

  ```
  Error while evaluating val loss: Dataset too small: minimum dataset(val) size is 147, but block size is 512. Either reduce block size or add more data.
  ```

  cela signifie que votre `block size` est trop grand pour l'ensemble de validation. Essayez de le rÃ©duire, par exemple Ã  128.
* Vous devriez maintenant voir les deux courbes de perte se mettre Ã  jour dynamiquement.
* Cliquez sur "DÃ©marrer l'entraÃ®nement" et attendez la fin de l'entraÃ®nement.

![EntraÃ®nement](https://github.com/ystemsrx/mini-nanoGPT/blob/master/assets/imgs/en_train.png?raw=true)

#### Mode Ã©valuation uniquement ?

* Ce mode vous permet d'Ã©valuer la perte du modÃ¨le sur l'ensemble de validation. RÃ©glez le `Nombre de graines d'Ã©valuation` sur une valeur > 0 pour activer le mode d'Ã©valuation uniquement. Vous verrez comment le modÃ¨le se comporte avec diffÃ©rentes graines alÃ©atoires.

### Ã‰tape 3 : GÃ©nÃ©rer du texte

1. Allez Ã  la page "InfÃ©rence"
2. Entrez une invite
3. Cliquez sur "GÃ©nÃ©rer" et voyez ce que le modÃ¨le propose !

![InfÃ©rence](https://github.com/ystemsrx/mini-nanoGPT/blob/master/assets/imgs/en_inference.png?raw=true)

### Ã‰tape 4 : Comparaison de modÃ¨les

1. Allez Ã  la page "Comparaison"
2. SÃ©lectionnez deux modÃ¨les Ã  comparer â€” ils peuvent mÃªme Ãªtre le mÃªme modÃ¨le avec des paramÃ¨tres diffÃ©rents
3. Leurs configurations seront affichÃ©es automatiquement
4. Vous pouvez entrer la mÃªme invite et voir comment les deux modÃ¨les gÃ©nÃ¨rent du texte
5. Ou, appliquez diffÃ©rents paramÃ¨tres d'infÃ©rence (tempÃ©rature, top_k, etc.) pour comparer les sorties

![Comparaison](https://github.com/ystemsrx/mini-nanoGPT/blob/master/assets/imgs/en_comparison.png?raw=true)

## ğŸ“ Structure du projet

```
mini-nanogpt/
â”œâ”€â”€ app.py           # Point d'entrÃ©e de l'application
â”œâ”€â”€ src/             # Configuration et modules principaux
â”œâ”€â”€ data/            # Stockage des donnÃ©es
â”œâ”€â”€ out/             # Points de contrÃ´le du modÃ¨le
â””â”€â”€ assets/          # Fichiers de tokenizer et autres ressources
```

## â“ FAQ

### C'est trop lent ?

* ğŸ’¡ Essayez de rÃ©duire la taille du lot ou la taille du modÃ¨le
* ğŸ’¡ Utilisez un GPU pour amÃ©liorer considÃ©rablement la vitesse
* ğŸ’¡ Augmentez l'intervalle d'Ã©valuation

### Le texte gÃ©nÃ©rÃ© n'est pas bon ?

* ğŸ’¡ Essayez d'augmenter les donnÃ©es d'entraÃ®nement
* ğŸ’¡ Ajustez les hyperparamÃ¨tres du modÃ¨le
* ğŸ’¡ Ajustez la tempÃ©rature pendant la gÃ©nÃ©ration

### Vous voulez reprendre un entraÃ®nement prÃ©cÃ©dent ?

* ğŸ’¡ Sur la page "EntraÃ®nement", sÃ©lectionnez "reprendre" sous Initialisation
* ğŸ’¡ Pointez vers le rÃ©pertoire de sortie prÃ©cÃ©dent

## ğŸ¤ Contribuer

Les suggestions et amÃ©liorations sont les bienvenues ! Vous pouvez :

* Soumettre une Issue
* Ouvrir une Pull Request
* Partager votre expÃ©rience d'utilisation de l'outil

## ğŸ“ Licence

Ce projet est open-source sous la [Licence MIT](LICENSE).

---

ğŸ‰ **Commencez votre voyage GPT maintenant !**
